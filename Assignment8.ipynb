{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment8.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPOyFeElz1sVWb8zCGRzSK1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/belikeamitesh/CS306-Machine-Learning/blob/main/Assignment8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gm04c19Lm0s_"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn import datasets\n",
        "from sklearn.metrics import accuracy_score\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn.datasets import load_iris"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "khxTQwbWnZNf"
      },
      "source": [
        "iris = datasets.load_iris()\n",
        "iris.feature_names\n",
        "data = pd.DataFrame(iris.data)\n",
        "# normalize the dataset\n",
        "max_val=max(data.max())\n",
        "data =data/max_val\n",
        "\n",
        "data.columns = iris.feature_names\n",
        "data\n",
        "iris.target.shape\n",
        "data['target'] = iris.target\n",
        "\n",
        "# 70% and 30% distribution\n",
        "train, test = np.split(data.sample(frac=1),[int(.7*len(data))])\n",
        "\n",
        "#Trainig dataset\n",
        "train_X =train.drop('target',axis='columns').values\n",
        "train_Y = train['target'].values\n",
        "\n",
        "#test dataset\n",
        "test_X =test.drop('target',axis='columns').values\n",
        "test_Y = test['target'].values\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-sls0vJVo0vC",
        "outputId": "67f6887f-20b0-49ba-e53a-11b67276adc6"
      },
      "source": [
        "print(train_Y)\n",
        "print(train_X.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 0 1 1 0 2 2 1 0 0 1 2 0 0 2 2 0 2 2 0 0 1 2 1 1 2 2 2 0 1 1 1 1 0 2 2 0\n",
            " 0 2 2 0 1 0 2 1 2 1 0 0 2 1 1 0 1 2 0 0 2 1 0 1 0 1 2 2 1 2 0 1 1 0 1 2 2\n",
            " 2 0 0 0 2 2 2 2 1 0 1 2 1 1 2 2 1 2 2 1 0 0 1 1 1 1 1 0 2 1 2]\n",
            "(105, 4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0VYHffToHUBW",
        "outputId": "a3e13609-64f5-42e6-9a06-4d3b04581001"
      },
      "source": [
        "print(test_Y)\n",
        "print(test_X.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 2 1 2 2 2 1 0 1 1 0 2 2 2 0 0 0 2 2 2 1 0 0 1 0 2 1 0 0 0 0 2 1 0 0 1 1\n",
            " 0 0 0 1 0 1 1 2]\n",
            "(45, 4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kGdy30C2ns6u"
      },
      "source": [
        "def oneHotEncoding(Y):\n",
        "  # for three classes -0,1,2, each output neuron represents one class\n",
        "  y1 = []\n",
        "  y2 = []\n",
        "  y3 = []\n",
        "  \n",
        "  for i in range(0 , len(Y)):\n",
        "    if (Y[i] == 0):\n",
        "      y1.append(1)\n",
        "      y2.append(0)\n",
        "      y3.append(0)\n",
        "    elif (Y[i] == 1):\n",
        "      y1.append(0)\n",
        "      y2.append(1)\n",
        "      y3.append(0)\n",
        "    else :\n",
        "      y1.append(0)\n",
        "      y2.append(0)\n",
        "      y3.append(1)\n",
        "    \n",
        "  return y1 ,y2 ,y3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "krUiGzzPoUHq"
      },
      "source": [
        "y1 , y2 , y3 = oneHotEncoding(train_Y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UK1dxYCyoYhH"
      },
      "source": [
        "def train_SLP(X , y1 , y2 , y3 , epoch, rho):\n",
        "  lr = 0.01\n",
        "  number_of_features = X.shape[1]\n",
        "  # initializing wij and cij\n",
        "  w1 = np.ones(shape=(number_of_features))*0.1\n",
        "  w2 = np.ones(shape=(number_of_features))*0.1\n",
        "  w3 = np.ones(shape=(number_of_features))*0.1\n",
        "  \n",
        "  error = []\n",
        "  for i in range(epoch ):\n",
        "    errorItr = 0;\n",
        "    for j in range(len(X)):\n",
        "       d1 = np.dot(w1, X[j].T)\n",
        "       d1 = 1 if d1 > 0 else 0\n",
        "       d2 = np.dot(w2, X[j].T)\n",
        "       d2 = 1 if d2 > 0 else 0\n",
        "       d3 = np.dot(w3, X[j].T)\n",
        "       d3 = 1 if d3 > 0 else 0\n",
        "      #  Erroritr = Errotitr + 1/2(summation of (dj-yj)^2)\n",
        "       errorItr = errorItr + ((d1- y1[j])*(d1 - y1[j]) + (d2- y2[j])*(d2 - y2[j]) + (d3- y3[j])*(d3 - y3[j]))/2\n",
        "      # update wij using  - wij = wij + alpha(yj-dj)*xj\n",
        "       w1 = w1 + lr*(y1[j] - d1)*X[j].T\n",
        "       w2 = w2 + lr*(y2[j]- d2)*X[j].T\n",
        "       w3 = w3 + lr*(y3[j]- d3)*X[j].T\n",
        "    # Converging Condition \n",
        "    if (errorItr < rho):\n",
        "      return w1 , w2  , w3 \n",
        "   \n",
        "    \n",
        "  return w1 , w2 , w3  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KEBcJHDHHkDR"
      },
      "source": [
        "def hyperprametertuning(d1,d2,d3):\n",
        "  correct_res= 0\n",
        "  for i in range(len(X)):\n",
        "    if (d1 > d2 and d1 > d3):\n",
        "      c0+=1\n",
        "    elif (d2 > d1 and d2 > d3):\n",
        "      c1+=1\n",
        "    else :\n",
        "      c3+=1 \n",
        "  return y\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XQpXLm9BpCkI"
      },
      "source": [
        "def predict(w1 , w2, w3 , X):\n",
        "  y = []\n",
        "  for i in range(len(X)):\n",
        "    d1 = np.dot(w1, X[i].T) \n",
        "    d2 = np.dot(w2, X[i].T) \n",
        "    d3 = np.dot(w3, X[i].T)\n",
        "    #classifying into diff classes\n",
        "    if (d1 > d2 and d1 > d3):\n",
        "      y.append(0)\n",
        "    elif (d2 > d1 and d2 > d3):\n",
        "      y.append(1)\n",
        "    else :\n",
        "      y.append(2) \n",
        "  return y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "axwUJKoTp2Nx",
        "outputId": "29c02e12-a7eb-4f49-9fc2-63bedb313ea4"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "w1 , w2 , w3    = train_SLP(train_X , y1 , y2, y3, 1000, 0.00001)\n",
        "y_predicted = predict(w1 , w2  , w3 , test_X)\n",
        "y_predicted = np.array(y_predicted)\n",
        "# print(y_predicted)\n",
        "print(\"Overall Accuracy : \",accuracy_score(  test_Y , y_predicted ))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overall Accuracy :  0.9555555555555556\n"
          ]
        }
      ]
    }
  ]
}